# Advanced Rate Limiting & API Management - Deep Dive
## Modern Solutions for AWS Bedrock Throttling

**Date:** November 18, 2025
**Focus:** Cutting-edge patterns, algorithms, and architectural solutions
**Goal:** Best-in-class system design for multi-user API management

---

## ğŸ“š Table of Contents

1. [Problem Deep Dive](#problem-deep-dive)
2. [Rate Limiting Algorithms Explained](#rate-limiting-algorithms)
3. [Modern Architectural Patterns](#modern-patterns)
4. [Industry Solutions Comparison](#industry-solutions)
5. [Recommended Advanced Solutions](#recommended-solutions)
6. [Step-by-Step Implementation](#implementation)
7. [Performance Optimization](#optimization)

---

## ğŸ” Problem Deep Dive

### Current Architecture Issues (Detailed Analysis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CURRENT SYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  User A â”€â”€â”                                                 â”‚
â”‚  User B â”€â”€â”¼â”€â†’ Flask â”€â”€â†’ AWS Bedrock (100 req/min limit)    â”‚
â”‚  User C â”€â”€â”˜     â†“                                           â”‚
â”‚               Direct                                         â”‚
â”‚               Calls                                          â”‚
â”‚                                                              â”‚
â”‚  Problems:                                                   â”‚
â”‚  âŒ No coordination between requests                        â”‚
â”‚  âŒ No rate tracking                                        â”‚
â”‚  âŒ Random throttling                                       â”‚
â”‚  âŒ No fairness guarantees                                  â”‚
â”‚  âŒ Poor resource utilization                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Traditional Solutions Fall Short

#### 1. **Simple Queue (Our Current Request Manager)** âš ï¸

**Approach:**
```python
queue = Queue()
while True:
    request = queue.get()
    process(request)
```

**Limitations:**
- âŒ **Head-of-line blocking**: One slow request blocks all others
- âŒ **No priority handling**: Important requests wait behind less important ones
- âŒ **Single server only**: Doesn't scale across multiple instances
- âŒ **Memory-based**: Lost on server restart
- âŒ **No adaptive behavior**: Fixed rate regardless of AWS availability

#### 2. **Celery Alone** âš ï¸

**Approach:**
```python
@celery_app.task
def analyze_section(content):
    return call_aws_bedrock(content)
```

**Limitations:**
- âŒ **No rate limiting**: Multiple workers still flood AWS
- âŒ **No coordination**: Workers don't communicate about rate limits
- âŒ **Fixed worker count**: Can't adapt to demand dynamically
- âŒ **Retry storms**: All workers retry simultaneously when throttled

---

## ğŸ¯ Rate Limiting Algorithms (From Basic to Advanced)

### 1. **Fixed Window Counter** (Basic)

**How it works:**
```python
# Count requests in fixed time windows
window = {
    '00:00-00:01': 25 requests,
    '00:01-00:02': 30 requests,
    '00:02-00:03': 28 requests
}

# Allow if count < limit
if window[current_minute] < 100:
    allow_request()
```

**Pros:**
- âœ… Simple to implement
- âœ… Low memory usage
- âœ… Fast lookups

**Cons:**
- âŒ **Burst problem**: Can get 200 requests in 2 seconds (100 at 00:00:59, 100 at 00:01:00)
- âŒ **Unfair**: Early requests in window get advantage
- âŒ **Edge case issues**: Window boundaries allow double traffic

**Visual:**
```
Minute 1: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 req âœ…
Minute 2: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 req âœ…
         ^
         â””â”€ 200 requests in 1 second! (burst at boundary)
```

**Rating:** â­â­â˜†â˜†â˜† (Too simple, has issues)

---

### 2. **Sliding Window Log** (Better)

**How it works:**
```python
# Store timestamp of each request
request_log = [
    1700000001.5,  # Request 1
    1700000002.3,  # Request 2
    1700000003.1,  # Request 3
    ...
]

# Count requests in last 60 seconds
current_time = time.time()
recent_requests = [r for r in request_log if r > current_time - 60]

if len(recent_requests) < 100:
    allow_request()
```

**Pros:**
- âœ… No burst problem (true sliding window)
- âœ… Accurate rate limiting
- âœ… Fair distribution

**Cons:**
- âŒ **High memory**: Stores every request timestamp
- âŒ **Slow with high traffic**: Must scan entire log each time
- âŒ **Scales poorly**: 1000 req/min = 1000 timestamps to store

**Example:**
```
Time: 00:00:55
Recent requests (last 60s):
[00:00:01] [00:00:05] [00:00:12] ... [00:00:54] â† 95 requests
Next request at 00:00:56: âœ… Allowed (95 < 100)

Time: 00:00:02 (next minute)
Still counting from 00:00:02 backwards 60 seconds
```

**Rating:** â­â­â­â˜†â˜† (Good but expensive)

---

### 3. **Sliding Window Counter** (Good Balance)

**How it works:**
```python
# Combine fixed windows with weighted counting
previous_window = 80 requests  # 00:00-00:01
current_window = 30 requests   # 00:01-00:02
current_second = 45  # 45 seconds into current window

# Weighted calculation
weight = (60 - current_second) / 60  # 15/60 = 0.25
estimated_count = (previous_window * weight) + current_window
# = (80 * 0.25) + 30 = 20 + 30 = 50 requests

if estimated_count < 100:
    allow_request()
```

**Pros:**
- âœ… Low memory (only 2 counters)
- âœ… Fast lookups
- âœ… No burst problem (smooths boundary)
- âœ… Good approximation of true sliding window

**Cons:**
- âš ï¸ Slight inaccuracy (estimates, doesn't track exactly)
- âš ï¸ Still has small burst possibility

**Visual:**
```
Previous Window: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80 req
Current Window:  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30 req
                      â†‘ We are here (45s into current)

Weighted count = (80 * 0.25) + 30 = 50 req
Still have 50 requests available âœ…
```

**Rating:** â­â­â­â­â˜† (Great balance)

---

### 4. **Token Bucket** â­â­â­â­â­ (RECOMMENDED)

**Concept:**
Imagine a bucket that holds tokens. Each request needs 1 token.
- Bucket refills at steady rate (e.g., 100 tokens/minute)
- Max capacity (e.g., 100 tokens)
- Request consumes 1 token
- If bucket empty, request rejected/queued

**How it works:**
```python
class TokenBucket:
    def __init__(self, capacity=100, refill_rate=100/60):  # 100 per minute
        self.capacity = capacity
        self.tokens = capacity
        self.refill_rate = refill_rate  # tokens per second
        self.last_refill = time.time()

    def consume(self, tokens=1):
        # Refill bucket based on time passed
        now = time.time()
        time_passed = now - self.last_refill
        new_tokens = time_passed * self.refill_rate

        self.tokens = min(self.capacity, self.tokens + new_tokens)
        self.last_refill = now

        # Try to consume
        if self.tokens >= tokens:
            self.tokens -= tokens
            return True  # Request allowed
        else:
            return False  # Request denied
```

**Pros:**
- âœ… **Allows bursts**: If idle, tokens accumulate (up to capacity)
- âœ… **Smooth traffic**: Steady refill rate prevents sustained overload
- âœ… **Simple**: Only tracks tokens and time
- âœ… **Memory efficient**: Just 3-4 variables
- âœ… **Adaptive**: Can adjust refill rate dynamically

**Cons:**
- âš ï¸ Requires time synchronization across servers (distributed case)

**Example Scenario:**
```
Initial state:
Bucket: [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 5 tokens, refills at 1 token/second

t=0s: User makes 3 requests
Bucket: [ğŸª™ğŸª™] 2 tokens remaining âœ… (3 requests allowed)

t=5s: Refilled +5 tokens (max 5)
Bucket: [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 5 tokens âœ…

t=6s: User makes 7 requests
Bucket: [] Empty after 5 requests âœ…
        2 requests denied âŒ (no tokens)

t=7s: Refilled +1 token
Bucket: [ğŸª™] 1 token
        Can process 1 of the 2 waiting requests
```

**Why Best for AWS Bedrock:**
- âœ… Handles burst traffic (user analyzes 5 sections quickly)
- âœ… Prevents sustained overload (steady refill matches AWS quota)
- âœ… Fair (first-come-first-served with token system)
- âœ… Efficient (minimal memory, fast checks)

**Rating:** â­â­â­â­â­ (Industry standard, best choice)

---

### 5. **Leaky Bucket** (Alternative)

**Concept:**
Imagine a bucket with a hole at the bottom. Requests drip out at constant rate.

```python
class LeakyBucket:
    def __init__(self, capacity=100, leak_rate=100/60):
        self.capacity = capacity
        self.queue = []
        self.leak_rate = leak_rate  # requests per second
        self.last_leak = time.time()

    def add_request(self, request):
        # Leak (process) requests that have waited long enough
        now = time.time()
        time_passed = now - self.last_leak
        requests_to_process = int(time_passed * self.leak_rate)

        for _ in range(min(requests_to_process, len(self.queue))):
            process(self.queue.pop(0))

        self.last_leak = now

        # Add new request to queue
        if len(self.queue) < self.capacity:
            self.queue.append(request)
            return True
        else:
            return False  # Queue full
```

**Pros:**
- âœ… **Constant output rate**: Perfect for smoothing traffic
- âœ… **Prevents bursts**: Forces steady pace
- âœ… **Simple queueing**: FIFO built-in

**Cons:**
- âŒ **No burst allowance**: Can't leverage idle periods
- âŒ **Higher latency**: All requests wait in queue

**Token Bucket vs Leaky Bucket:**
```
Token Bucket:
User idle â†’ Tokens accumulate â†’ Burst of requests â†’ All served quickly âœ…

Leaky Bucket:
User idle â†’ Nothing happens â†’ Burst of requests â†’ Served slowly one-by-one â³
```

**When to use:**
- **Token Bucket**: When you want to allow bursts (better UX)
- **Leaky Bucket**: When you need absolutely constant output rate

**For our case:** Token Bucket is better (users expect burst handling)

**Rating:** â­â­â­â­â˜† (Good, but Token Bucket more flexible)

---

### 6. **Adaptive Rate Limiting** (Advanced) â­â­â­â­â­

**Concept:**
Rate limit adjusts based on AWS responses. If throttled, reduce rate. If successful, increase rate.

```python
class AdaptiveRateLimiter:
    def __init__(self):
        self.current_rate = 100  # Start at 100 req/min
        self.min_rate = 10
        self.max_rate = 200
        self.success_count = 0
        self.throttle_count = 0

    def on_success(self):
        self.success_count += 1

        # After 100 successes, try increasing rate
        if self.success_count >= 100:
            self.current_rate = min(self.max_rate, self.current_rate * 1.1)
            self.success_count = 0
            print(f"ğŸ“ˆ Increased rate to {self.current_rate} req/min")

    def on_throttle(self):
        self.throttle_count += 1

        # Immediately reduce rate on throttle
        self.current_rate = max(self.min_rate, self.current_rate * 0.5)
        self.throttle_count = 0
        print(f"ğŸ“‰ Reduced rate to {self.current_rate} req/min")

    def get_current_rate(self):
        return self.current_rate
```

**Pros:**
- âœ… **Self-tuning**: Automatically finds optimal rate
- âœ… **Adapts to AWS changes**: If AWS increases quota, system discovers it
- âœ… **Handles degradation**: Backs off during AWS issues
- âœ… **No manual configuration**: Learns optimal rate

**Cons:**
- âš ï¸ Requires monitoring feedback from AWS
- âš ï¸ Takes time to converge to optimal rate

**Example:**
```
Start: 100 req/min
â†“
AWS throttles â†’ Reduce to 50 req/min
â†“
100 successes â†’ Increase to 55 req/min
â†“
100 successes â†’ Increase to 60 req/min
â†“
AWS throttles â†’ Reduce to 30 req/min
â†“
Converges to: ~45 req/min (optimal for current conditions)
```

**Rating:** â­â­â­â­â­ (Best for production, requires monitoring)

---

## ğŸ—ï¸ Modern Architectural Patterns

### Pattern 1: **Circuit Breaker** â­â­â­â­â­

**Concept:**
Like an electrical circuit breaker - if AWS keeps failing, "trip" the circuit and stop trying.

**States:**
1. **Closed** (Normal): Requests flow through
2. **Open** (Tripped): Requests immediately rejected (don't even try AWS)
3. **Half-Open** (Testing): Periodically test if AWS recovered

```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.state = 'CLOSED'
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.last_failure_time = None

    def call(self, func, *args):
        if self.state == 'OPEN':
            # Circuit is open, check if timeout passed
            if time.time() - self.last_failure_time > self.timeout:
                self.state = 'HALF_OPEN'
                print("ğŸ”„ Circuit breaker: Testing recovery...")
            else:
                print("âš¡ Circuit breaker: OPEN, using fallback")
                return self.fallback()

        try:
            result = func(*args)
            self.on_success()
            return result
        except ThrottlingError:
            self.on_failure()
            return self.fallback()

    def on_success(self):
        self.failure_count = 0
        if self.state == 'HALF_OPEN':
            self.state = 'CLOSED'
            print("âœ… Circuit breaker: CLOSED, AWS recovered")

    def on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()

        if self.failure_count >= self.failure_threshold:
            self.state = 'OPEN'
            print("ğŸ”´ Circuit breaker: OPEN, AWS unavailable")

    def fallback(self):
        # Return mock response or cached data
        return mock_response()
```

**Visual:**
```
Normal operation (CLOSED):
Request â†’ AWS â†’ Success âœ…
Request â†’ AWS â†’ Success âœ…
Request â†’ AWS â†’ Throttle âŒ (count: 1)
Request â†’ AWS â†’ Throttle âŒ (count: 2)
Request â†’ AWS â†’ Throttle âŒ (count: 3)
Request â†’ AWS â†’ Throttle âŒ (count: 4)
Request â†’ AWS â†’ Throttle âŒ (count: 5)
â†“
Circuit OPENS âš¡

Circuit OPEN (60 seconds):
Request â†’ âš¡ REJECTED â†’ Mock response âœ… (instant)
Request â†’ âš¡ REJECTED â†’ Mock response âœ… (instant)
â†“ (after 60s)
Circuit HALF-OPEN ğŸ”„

Testing (HALF-OPEN):
Request â†’ AWS â†’ Success âœ…
â†“
Circuit CLOSES âœ… (back to normal)
```

**Benefits:**
- âœ… **Prevents cascade failures**: Stops overwhelming AWS when it's down
- âœ… **Fast fail**: Don't waste time on requests that will fail
- âœ… **Automatic recovery**: Tests AWS periodically
- âœ… **Better UX**: Users get immediate fallback instead of waiting for timeout

**Rating:** â­â­â­â­â­ (Essential for production)

---

### Pattern 2: **Backpressure** (Reactive Streams)

**Concept:**
When system is overloaded, signal upstream to slow down.

```python
class BackpressureHandler:
    def __init__(self, max_pending=10):
        self.max_pending = max_pending
        self.pending_requests = 0

    def try_submit(self, request):
        if self.pending_requests >= self.max_pending:
            # System overloaded, apply backpressure
            return {
                'accepted': False,
                'reason': 'System overloaded',
                'retry_after': 30  # seconds
            }

        self.pending_requests += 1
        return {'accepted': True}

    def on_complete(self):
        self.pending_requests -= 1
```

**Frontend handles backpressure:**
```javascript
async function analyzeSection(section) {
    const response = await fetch('/analyze', {
        body: JSON.stringify({section})
    });

    if (response.status === 429) {  // Too Many Requests
        const retryAfter = response.headers.get('Retry-After');
        showMessage(`System busy, please wait ${retryAfter}s`);
        await sleep(retryAfter * 1000);
        return analyzeSection(section);  // Retry
    }

    return response.json();
}
```

**Benefits:**
- âœ… **Prevents overload**: System explicitly rejects when capacity reached
- âœ… **Graceful degradation**: Users get clear feedback
- âœ… **Automatic retry**: Client knows when to retry

**Rating:** â­â­â­â­â˜† (Good for high-scale systems)

---

### Pattern 3: **Request Coalescing** (Batching)

**Concept:**
If multiple users request same analysis, do it once and share result.

```python
class RequestCoalescer:
    def __init__(self):
        self.pending = {}  # key -> Future

    async def analyze(self, content_hash, content):
        if content_hash in self.pending:
            # Same content being analyzed, wait for existing request
            print(f"ğŸ”— Coalescing request for {content_hash}")
            return await self.pending[content_hash]

        # New content, create future
        future = asyncio.Future()
        self.pending[content_hash] = future

        try:
            result = await call_aws_bedrock(content)
            future.set_result(result)
            return result
        finally:
            del self.pending[content_hash]
```

**Example:**
```
User A: Analyzes "Executive Summary" â†’ AWS Call #1 (in progress)
User B: Analyzes "Executive Summary" (same text) â†’ Waits for Call #1 âœ…
User C: Analyzes "Executive Summary" (same text) â†’ Waits for Call #1 âœ…

Result: 3 users, 1 AWS call (saves 2 API calls!)
```

**Benefits:**
- âœ… **Reduces API calls**: Especially for popular documents
- âœ… **Faster for subsequent users**: No AWS wait time
- âœ… **Lower costs**: Fewer API calls

**Limitations:**
- âš ï¸ Only works for identical content
- âš ï¸ Requires content hashing
- âš ï¸ Short time window (only during request)

**Rating:** â­â­â­â­â˜† (Great for specific use cases)

---

### Pattern 4: **Staged Event-Driven Architecture (SEDA)**

**Concept:**
Break processing into stages with queues between them.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Receive  â”‚ â†’  â”‚ Validate â”‚ â†’  â”‚ Rate     â”‚ â†’  â”‚ Process  â”‚
â”‚ Request  â”‚    â”‚ Request  â”‚    â”‚ Limit    â”‚    â”‚ with AWS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“               â†“               â†“               â†“
  [Queue 1]      [Queue 2]      [Queue 3]      [Queue 4]
```

**Each stage:**
- Has its own thread pool
- Can scale independently
- Has monitoring/backpressure

**Benefits:**
- âœ… **Isolation**: One slow stage doesn't block others
- âœ… **Scalability**: Scale each stage independently
- âœ… **Observability**: Monitor each stage separately

**Rating:** â­â­â­â­â­ (Enterprise-grade architecture)

---

## ğŸŒ Industry Solutions Comparison

### Solution 1: **Redis-based Rate Limiter** â­â­â­â­â­

**Used by:** Twitter, GitHub, Stripe

**How it works:**
```python
import redis

class RedisRateLimiter:
    def __init__(self):
        self.redis = redis.Redis()

    def check_rate_limit(self, user_id, limit=100, window=60):
        key = f"rate_limit:{user_id}:{int(time.time() // window)}"

        current = self.redis.incr(key)

        if current == 1:
            self.redis.expire(key, window * 2)  # Set expiry

        return current <= limit
```

**Pros:**
- âœ… **Distributed**: Works across multiple servers
- âœ… **Fast**: Redis is in-memory
- âœ… **Persistent**: Survives app restarts
- âœ… **Atomic**: Thread-safe operations

**Implementation with Token Bucket:**
```lua
-- Redis Lua script for atomic token bucket
local key = KEYS[1]
local capacity = tonumber(ARGV[1])
local refill_rate = tonumber(ARGV[2])
local requested = tonumber(ARGV[3])
local now = tonumber(ARGV[4])

local bucket = redis.call('HMGET', key, 'tokens', 'last_refill')
local tokens = tonumber(bucket[1]) or capacity
local last_refill = tonumber(bucket[2]) or now

-- Refill tokens
local time_passed = now - last_refill
local new_tokens = time_passed * refill_rate
tokens = math.min(capacity, tokens + new_tokens)

-- Try to consume
if tokens >= requested then
    tokens = tokens - requested
    redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)
    redis.call('EXPIRE', key, 120)
    return {1, tokens}  -- Success
else
    return {0, tokens}  -- Denied
end
```

**Rating:** â­â­â­â­â­ (Production-ready, scales well)

---

### Solution 2: **Kong API Gateway** (Commercial)

**What it is:** Full-featured API gateway with rate limiting built-in

**Features:**
- Rate limiting (multiple algorithms)
- Load balancing
- Authentication
- Caching
- Monitoring

**Configuration:**
```yaml
plugins:
  - name: rate-limiting
    config:
      minute: 100
      policy: redis
      redis_host: localhost
      redis_port: 6379
```

**Pros:**
- âœ… Production-tested
- âœ… Multiple algorithms
- âœ… Enterprise support

**Cons:**
- âŒ Additional infrastructure
- âŒ Learning curve
- âŒ May be overkill

**Rating:** â­â­â­â­â˜† (Great for large systems)

---

### Solution 3: **AWS API Gateway** (Cloud-native)

**What it is:** AWS's managed API gateway

**Features:**
- Built-in rate limiting
- AWS integration
- Auto-scaling
- Pay-per-use

**Configuration:**
```python
# Set usage plan
usage_plan = apigateway.create_usage_plan(
    name='BedcockAccess',
    throttle={
        'rateLimit': 100.0,  # requests per second
        'burstLimit': 200    # burst capacity
    }
)
```

**Pros:**
- âœ… Fully managed
- âœ… Scales automatically
- âœ… Integrated with AWS

**Cons:**
- âŒ AWS vendor lock-in
- âŒ Additional cost
- âŒ Less control

**Rating:** â­â­â­â­â˜† (Best for AWS-heavy setups)

---

### Solution 4: **NGINX Rate Limiting** (Open Source)

**Configuration:**
```nginx
http {
    limit_req_zone $binary_remote_addr zone=bedrock:10m rate=100r/m;

    server {
        location /analyze {
            limit_req zone=bedrock burst=20 nodelay;
            proxy_pass http://flask_backend;
        }
    }
}
```

**Pros:**
- âœ… Free and open source
- âœ… Battle-tested
- âœ… High performance

**Cons:**
- âš ï¸ Configuration complexity
- âš ï¸ Less flexible than custom solution

**Rating:** â­â­â­â­â˜† (Good for infrastructure-based limiting)

---

## ğŸ¯ Recommended Solution (Best Practice)

### **Hybrid Architecture: Multi-Layer Rate Limiting**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECOMMENDED ARCHITECTURE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Layer 1: NGINX (Infrastructure)                            â”‚
â”‚  â”œâ”€ Rough rate limiting (200 req/min)                       â”‚
â”‚  â”œâ”€ DDoS protection                                         â”‚
â”‚  â””â”€ Load balancing                                          â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 2: Flask + Redis Token Bucket (Application)          â”‚
â”‚  â”œâ”€ Precise rate limiting (100 req/min)                     â”‚
â”‚  â”œâ”€ Per-user fairness                                       â”‚
â”‚  â”œâ”€ Token bucket algorithm                                  â”‚
â”‚  â””â”€ Distributed across servers                              â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 3: Celery + Request Manager (Processing)             â”‚
â”‚  â”œâ”€ Async task processing                                   â”‚
â”‚  â”œâ”€ Request queuing                                         â”‚
â”‚  â”œâ”€ Worker pool management                                  â”‚
â”‚  â””â”€ Connection pooling                                      â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 4: Circuit Breaker (Protection)                      â”‚
â”‚  â”œâ”€ Detect AWS failures                                     â”‚
â”‚  â”œâ”€ Fast fail when AWS down                                 â”‚
â”‚  â”œâ”€ Automatic recovery testing                              â”‚
â”‚  â””â”€ Fallback to mock                                        â”‚
â”‚                          â†“                                   â”‚
â”‚  Layer 5: Adaptive Rate Limiter (Intelligence)              â”‚
â”‚  â”œâ”€ Monitor AWS responses                                   â”‚
â”‚  â”œâ”€ Adjust rate dynamically                                 â”‚
â”‚  â”œâ”€ Learn optimal throughput                                â”‚
â”‚  â””â”€ Handle AWS quota changes                                â”‚
â”‚                          â†“                                   â”‚
â”‚                    â˜ï¸ AWS Bedrock                            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This is Best:

1. **Defense in Depth**: Multiple layers catch issues
2. **Separation of Concerns**: Each layer handles specific problem
3. **Scalability**: Each layer can scale independently
4. **Reliability**: Failure in one layer doesn't break system
5. **Observability**: Monitor each layer separately

---

## ğŸ“ Step-by-Step Implementation Guide

I'll create a detailed implementation of the recommended solution in the next file...

**Rating:** â­â­â­â­â­ (Enterprise-grade, production-ready)

---

**Continue to:** [ADVANCED_IMPLEMENTATION_GUIDE.md](#) for complete code implementation

