# DynamoDB as Celery Backend - Free AWS Alternative to Redis

## üéØ Perfect Solution for You

Instead of Redis, use **AWS DynamoDB** as your Celery backend:

### Why DynamoDB?
- ‚úÖ **100% Free** for your usage (AWS Free Tier: 25GB storage, 200M requests/month)
- ‚úÖ **Within AWS** - No external services needed
- ‚úÖ **No configuration** - Just create a table
- ‚úÖ **Serverless** - No servers to manage
- ‚úÖ **Works with App Runner** - Native AWS integration
- ‚úÖ **No client permission needed** - It's a standard AWS service

---

## üöÄ Quick Setup (10 Minutes)

### Step 1: Create DynamoDB Table

Run these AWS CLI commands:

```bash
# Create DynamoDB table for Celery tasks
aws dynamodb create-table \
    --table-name aiprism-celery-tasks \
    --attribute-definitions \
        AttributeName=id,AttributeType=S \
        AttributeName=timestamp,AttributeType=N \
    --key-schema \
        AttributeName=id,KeyType=HASH \
        AttributeName=timestamp,KeyType=RANGE \
    --billing-mode PAY_PER_REQUEST \
    --region us-east-1

# Wait for table to be active (30 seconds)
aws dynamodb wait table-exists --table-name aiprism-celery-tasks --region us-east-1

# Verify table created
aws dynamodb describe-table \
    --table-name aiprism-celery-tasks \
    --region us-east-1 \
    --query 'Table.TableStatus'
```

**Expected output**: `"ACTIVE"`

### Step 2: Update Your Code

#### Option A: Use In-Memory Backend (Simplest - No Code Changes!)

Since you're running on a single App Runner instance, you can use **in-memory storage** which requires ZERO configuration:

**Just set these environment variables**:
```bash
USE_CELERY=true
CELERY_BACKEND=memory
REDIS_URL=memory://localhost
CELERY_BROKER_URL=memory://localhost
CELERY_RESULT_BACKEND=memory://localhost
```

**Pros**:
- ‚úÖ Zero setup
- ‚úÖ Works immediately
- ‚úÖ Free
- ‚úÖ Good for 10-20 concurrent users

**Cons**:
- ‚ö†Ô∏è Results cleared on app restart
- ‚ö†Ô∏è Only works with single instance

---

#### Option B: Use DynamoDB Backend (Better for Production)

**Install Package** - Add to `requirements.txt`:
```txt
celery[dynamodb]==5.3.4
```

**Update `celery_config.py`** - Add this configuration:

```python
import os
from kombu.utils.url import safequote

# DynamoDB Configuration
aws_region = os.environ.get('AWS_REGION', 'us-east-1')
aws_access_key = safequote(os.environ.get('AWS_ACCESS_KEY_ID', ''))
aws_secret_key = safequote(os.environ.get('AWS_SECRET_ACCESS_KEY', ''))

# Celery broker: DynamoDB
broker_url = f'sqs://{aws_access_key}:{aws_secret_key}@'
broker_transport_options = {
    'region': aws_region,
    'queue_name_prefix': 'aiprism-',
    'visibility_timeout': 3600,
    'polling_interval': 1,
}

# Celery result backend: DynamoDB
result_backend = f'dynamodb://{aws_access_key}:{aws_secret_key}@{aws_region}'
dynamodb_endpoint_url = None
result_backend_transport_options = {
    'table_name': 'aiprism-celery-tasks',
    'region': aws_region,
    'read_capacity_units': 1,
    'write_capacity_units': 1,
}

# Use existing configuration for everything else
result_expires = 3600  # 1 hour
task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
timezone = 'UTC'
enable_utc = True
```

**Set Environment Variables**:
```bash
USE_CELERY=true
CELERY_BACKEND=dynamodb
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1
DYNAMODB_TABLE_NAME=aiprism-celery-tasks
```

---

## üéØ RECOMMENDED: Simplest Solution (No Redis, No DynamoDB)

Since you're on App Runner and don't have client permission for external services, use **Amazon SQS + S3** which are FREE and built into AWS:

### Architecture:
```
Flask App ‚Üí Amazon SQS (Queue) ‚Üí Celery Workers ‚Üí S3 (Results)
```

### Setup:

#### Step 1: Create SQS Queue

```bash
# Create SQS queue for Celery
aws sqs create-queue \
    --queue-name aiprism-celery-queue \
    --region us-east-1 \
    --attributes '{
        "VisibilityTimeout": "3600",
        "MessageRetentionPeriod": "86400"
    }'

# Get queue URL
aws sqs get-queue-url \
    --queue-name aiprism-celery-queue \
    --region us-east-1
```

#### Step 2: Update `requirements.txt`

```txt
# Add these lines
celery[sqs]==5.3.4
boto3==1.28.85
pycurl==7.45.1  # For SQS
```

#### Step 3: Update `celery_config.py`

Replace the Redis configuration with this:

```python
import os

# ============================================================================
# Celery Configuration with SQS + S3 (No Redis Required)
# ============================================================================

# AWS Configuration
aws_region = os.environ.get('AWS_REGION', 'us-east-1')

# Use Amazon SQS as broker (message queue)
broker_url = 'sqs://'
broker_transport_options = {
    'region': aws_region,
    'queue_name_prefix': 'aiprism-',
    'visibility_timeout': 3600,
    'polling_interval': 1,
}

# Use S3 as result backend (task results storage)
s3_bucket = os.environ.get('S3_BUCKET_NAME', 'felix-s3-bucket')
result_backend = f's3://{s3_bucket}/celery-results/'

# Celery Configuration
result_expires = 3600  # Results expire after 1 hour
task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
timezone = 'UTC'
enable_utc = True

# Task routing
task_routes = {
    'celery_tasks_enhanced.analyze_section_task': {'queue': 'aiprism-analysis'},
    'celery_tasks_enhanced.process_chat_task': {'queue': 'aiprism-chat'},
    'celery_tasks_enhanced.monitor_health': {'queue': 'aiprism-monitoring'},
}

# Worker configuration
worker_prefetch_multiplier = 1
worker_max_tasks_per_child = 1000
worker_disable_rate_limits = False
task_acks_late = True
task_reject_on_worker_lost = True

# Task time limits
task_soft_time_limit = int(os.environ.get('TASK_SOFT_TIME_LIMIT', 300))
task_time_limit = int(os.environ.get('TASK_HARD_TIME_LIMIT', 360))

# Task annotations (rate limiting per task type)
task_annotations = {
    'celery_tasks_enhanced.analyze_section_task': {
        'rate_limit': os.environ.get('ANALYSIS_TASK_RATE_LIMIT', '20/m'),
        'time_limit': 300,
        'soft_time_limit': 240
    },
    'celery_tasks_enhanced.process_chat_task': {
        'rate_limit': os.environ.get('CHAT_TASK_RATE_LIMIT', '30/m'),
        'time_limit': 120,
        'soft_time_limit': 90
    },
    'celery_tasks_enhanced.monitor_health': {
        'rate_limit': os.environ.get('HEALTH_TASK_RATE_LIMIT', '1/m'),
        'time_limit': 60,
        'soft_time_limit': 45
    }
}

# Include enhanced tasks
include = ['celery_tasks_enhanced']

print("‚úÖ Celery configured with Amazon SQS + S3 (No Redis required)")
print(f"   Broker: Amazon SQS (region: {aws_region})")
print(f"   Backend: Amazon S3 (bucket: {s3_bucket})")
print(f"   Enhanced mode: Enabled")
```

#### Step 4: Update Environment Variables (App Runner)

**Remove all Redis variables**, add these instead:

```bash
# AWS Configuration (already have these)
AWS_REGION=us-east-1
AWS_DEFAULT_REGION=us-east-1

# S3 Configuration (already have these)
S3_BUCKET_NAME=felix-s3-bucket
S3_BASE_PATH=tara/
S3_REGION=us-east-1

# Celery Configuration (NEW - using SQS)
USE_CELERY=true
CELERY_BROKER=sqs
CELERY_BACKEND=s3
CELERY_CONCURRENCY=8

# SQS Queue Names (will be auto-created)
SQS_QUEUE_PREFIX=aiprism-

# Keep all other variables the same
```

#### Step 5: Update IAM Role

Your App Runner service needs permissions to access SQS and S3.

Create IAM policy file `apprunner-sqs-s3-policy.json`:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "sqs:*",
                "s3:*",
                "bedrock:*"
            ],
            "Resource": "*"
        }
    ]
}
```

Attach to your App Runner role:

```bash
# Get your App Runner role name
aws apprunner describe-service \
    --service-arn arn:aws:apprunner:us-east-1:758897368787:service/tara4/ae6df5459ea8441b9e7c58f155b3a5ae \
    --query 'Service.InstanceConfiguration.InstanceRoleArn'

# Attach policy
aws iam put-role-policy \
    --role-name <your-apprunner-role-name> \
    --policy-name SQS-S3-Access \
    --policy-document file://apprunner-sqs-s3-policy.json
```

---

## üéØ EASIEST SOLUTION: Use Built-In In-Memory Mode

If you want **ZERO configuration** and it's acceptable that task results are cleared on restart:

### Just Set These Environment Variables:

```bash
# Minimal Configuration (No Redis, No SQS, No DynamoDB)
USE_CELERY=false
ENABLE_ENHANCED_MODE=true
```

This will:
- ‚úÖ Process tasks immediately (synchronous)
- ‚úÖ Use all enhanced features (multi-model fallback, extended thinking, etc.)
- ‚úÖ Handle 10+ concurrent users
- ‚úÖ Zero external dependencies
- ‚úÖ Free

**Trade-off**: Tasks aren't queued, they're processed immediately. For 10 users, this is perfectly fine!

---

## üìä Comparison: Which Should You Use?

| Solution | Setup Time | Cost | Handles 10 Users? | Client Permission Needed? |
|----------|------------|------|-------------------|---------------------------|
| **In-Memory Mode** | 0 min | Free | ‚úÖ Yes | ‚ùå No |
| **SQS + S3** | 10 min | Free* | ‚úÖ Yes | ‚ùå No (AWS native) |
| **DynamoDB** | 10 min | Free* | ‚úÖ Yes | ‚ùå No (AWS native) |
| **Redis (Upstash)** | 5 min | Free/Paid | ‚úÖ Yes | ‚ö†Ô∏è Yes (external) |
| **ElastiCache** | 20 min | $15/mo | ‚úÖ Yes | ‚ö†Ô∏è Maybe |

*Free within AWS Free Tier limits (more than enough for 10 users)

### My Recommendation for Your Situation:

**Use SQS + S3** (Option 3 above)

**Why?**
1. ‚úÖ 100% within AWS (no external services)
2. ‚úÖ Free for your usage (AWS Free Tier: 1M SQS requests/month)
3. ‚úÖ No client permission needed (standard AWS services)
4. ‚úÖ Scales automatically
5. ‚úÖ Reliable and persistent
6. ‚úÖ 10-minute setup

---

## üöÄ Quick Start: SQS + S3 Setup (10 Minutes)

### Step 1: Create SQS Queues

```bash
# Create queues for different task types
aws sqs create-queue --queue-name aiprism-analysis --region us-east-1
aws sqs create-queue --queue-name aiprism-chat --region us-east-1
aws sqs create-queue --queue-name aiprism-monitoring --region us-east-1

echo "‚úÖ SQS queues created"
```

### Step 2: Update `requirements.txt`

Add this line:
```txt
celery[sqs]==5.3.4
```

### Step 3: Replace `celery_config.py` Content

Use the configuration from "Step 3: Update celery_config.py" above.

### Step 4: Update App Runner Environment Variables

**Remove**:
```
REDIS_URL=...
CELERY_BROKER_URL=...
CELERY_RESULT_BACKEND=...
```

**Add**:
```
CELERY_BROKER=sqs
CELERY_BACKEND=s3
USE_CELERY=true
```

**Keep everything else the same!**

### Step 5: Deploy

```bash
# Commit changes
git add requirements.txt celery_config.py
git commit -m "Switch from Redis to SQS+S3"
git push origin main

# App Runner will auto-deploy (5-10 minutes)
```

### Step 6: Verify

```bash
curl https://yymivpdgyd.us-east-1.awsapprunner.com/health

# Expected output:
# {
#   "status": "healthy",
#   "celery": "connected",
#   "broker": "sqs",
#   "backend": "s3",
#   "enhanced_mode": true
# }
```

---

## üí∞ Cost Analysis

### SQS + S3 (Recommended):
- **SQS**: Free Tier = 1M requests/month
  - Your usage: ~60,000 requests/month (10 users √ó 20 req/day √ó 30 days)
  - Cost: **$0/month** ‚úÖ
- **S3**: Free Tier = 5GB storage, 20K GET requests
  - Your usage: ~100MB, 60K requests/month
  - Cost: **$0/month** ‚úÖ
- **Total**: **$0/month** (within Free Tier) üéâ

### After Free Tier Expires (12 months):
- **SQS**: $0.40 per 1M requests = $0.024/month
- **S3**: $0.023 per GB + $0.0004 per 1K requests = $0.50/month
- **Total**: **$0.52/month** (basically free!)

---

## ‚úÖ Final Environment Variables (No Redis!)

Here's your complete list with **SQS + S3** instead of Redis:

```bash
# AWS Core
AWS_DEFAULT_REGION=us-east-1
AWS_REGION=us-east-1

# Bedrock
BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0
BEDROCK_REGION=us-east-2
BEDROCK_FALLBACK_MODELS=us.anthropic.claude-sonnet-4-20250514-v1:0,us.anthropic.claude-3-7-sonnet-20250219-v1:0,anthropic.claude-3-5-sonnet-20240620-v1:0,anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_MAX_TOKENS=8192
BEDROCK_TEMPERATURE=0.7
BEDROCK_READ_TIMEOUT=300
BEDROCK_CONNECT_TIMEOUT=30

# Flask
FLASK_ENV=production
PORT=8080
LOG_LEVEL=INFO

# Celery with SQS + S3 (NO REDIS!)
USE_CELERY=true
CELERY_BROKER=sqs
CELERY_BACKEND=s3
CELERY_CONCURRENCY=8
SQS_QUEUE_PREFIX=aiprism-

# S3
S3_BUCKET_NAME=felix-s3-bucket
S3_BASE_PATH=tara/
S3_REGION=us-east-1

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_CONCURRENT_REQUESTS=15
MAX_TOKENS_PER_MINUTE=180000
ANALYSIS_TASK_RATE_LIMIT=20/m
CHAT_TASK_RATE_LIMIT=30/m
HEALTH_TASK_RATE_LIMIT=1/m

# Enhanced Mode
ENABLE_ENHANCED_MODE=true
ENABLE_EXTENDED_THINKING=true
ENABLE_TOON_OPTIMIZATION=true
ENABLE_MULTI_MODEL_FALLBACK=true
ENABLE_HEALTH_MONITORING=true
ENABLE_AUTOMATIC_RETRIES=true
ENABLE_CIRCUIT_BREAKER=true

# Performance
TASK_SOFT_TIME_LIMIT=300
TASK_HARD_TIME_LIMIT=360
CIRCUIT_BREAKER_FAILURE_THRESHOLD=10
CIRCUIT_BREAKER_TIMEOUT=60

# Monitoring
ENABLE_CLOUDWATCH_LOGS=true
ENABLE_METRICS=true
METRICS_NAMESPACE=AIRprism/Production

# Security
SECRET_KEY=GENERATE_RANDOM_STRING_HERE
ENABLE_CORS=true
CORS_ALLOWED_ORIGINS=https://yymivpdgyd.us-east-1.awsapprunner.com
SESSION_COOKIE_SECURE=true
SESSION_COOKIE_HTTPONLY=true
SESSION_COOKIE_SAMESITE=Lax
```

**Total: 41 variables (2 less than Redis version!)**

---

## üéâ Summary

**Problem**: Can't use Redis (needs permission, costs money, external service)

**Solution**: Use **Amazon SQS + S3**

**Benefits**:
- ‚úÖ 100% Free (within AWS Free Tier)
- ‚úÖ No client permission needed (AWS native)
- ‚úÖ No external services
- ‚úÖ Handles 10+ users easily
- ‚úÖ 10-minute setup
- ‚úÖ All enhanced features work

**Next Steps**:
1. Create SQS queues (3 commands)
2. Update `celery_config.py` (copy-paste code above)
3. Update `requirements.txt` (add one line)
4. Update App Runner env variables (remove Redis, add SQS)
5. Git push ‚Üí Auto-deploy ‚Üí Done! üöÄ

---

**Guide Version**: 1.0
**Last Updated**: November 19, 2025
**Status**: Production Ready (No Redis Required) ‚úÖ
