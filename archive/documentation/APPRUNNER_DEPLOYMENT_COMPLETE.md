# App Runner Deployment - Complete Guide

**Production-Ready Deployment for AI-Prism**

---

## ğŸ¯ What You Have Now

Your App Runner deployment at:
```
https://yymivpdgyd.us-east-1.awsapprunner.com
```

**Status**: âœ… Running, but needs SQS queues configured

---

## ğŸ“‹ Quick Setup (25 Minutes)

### Step 1: Create SQS Queues (15 minutes)

Open your terminal and run:

```bash
# Set your region
export AWS_REGION=us-east-2

# Create the 3 required queues
aws sqs create-queue --queue-name aiprism-analysis --region $AWS_REGION
aws sqs create-queue --queue-name aiprism-chat --region $AWS_REGION
aws sqs create-queue --queue-name aiprism-monitoring --region $AWS_REGION

# Configure analysis queue (long timeout for AI processing)
ANALYSIS_QUEUE_URL=$(aws sqs get-queue-url --queue-name aiprism-analysis --region $AWS_REGION --query 'QueueUrl' --output text)

aws sqs set-queue-attributes \
    --queue-url $ANALYSIS_QUEUE_URL \
    --attributes '{
        "VisibilityTimeout": "3600",
        "MessageRetentionPeriod": "86400",
        "ReceiveMessageWaitTimeSeconds": "1"
    }' \
    --region $AWS_REGION

# Configure chat queue
CHAT_QUEUE_URL=$(aws sqs get-queue-url --queue-name aiprism-chat --region $AWS_REGION --query 'QueueUrl' --output text)

aws sqs set-queue-attributes \
    --queue-url $CHAT_QUEUE_URL \
    --attributes '{
        "VisibilityTimeout": "300",
        "MessageRetentionPeriod": "86400",
        "ReceiveMessageWaitTimeSeconds": "1"
    }' \
    --region $AWS_REGION

# Configure monitoring queue
MONITORING_QUEUE_URL=$(aws sqs get-queue-url --queue-name aiprism-monitoring --region $AWS_REGION --query 'QueueUrl' --output text)

aws sqs set-queue-attributes \
    --queue-url $MONITORING_QUEUE_URL \
    --attributes '{
        "VisibilityTimeout": "300",
        "MessageRetentionPeriod": "86400",
        "ReceiveMessageWaitTimeSeconds": "1"
    }' \
    --region $AWS_REGION

echo "âœ… All queues configured!"
```

---

### Step 2: Update App Runner Configuration (10 minutes)

1. **Go to App Runner Console**:
   ```
   https://console.aws.amazon.com/apprunner/
   ```

2. **Select your service**: `tara4`

3. **Click**: Configuration â†’ Edit (Environment variables section)

4. **Add/Update these variables**:

```bash
# AWS Configuration
AWS_REGION=us-east-2
AWS_DEFAULT_REGION=us-east-2
S3_BUCKET_NAME=felix-s3-bucket
S3_BASE_PATH=tara/
SQS_QUEUE_PREFIX=aiprism-

# Flask Configuration
FLASK_ENV=production
FLASK_DEBUG=False
PORT=8080
SECRET_KEY=your-production-secret-key-change-this

# Bedrock AI Configuration
BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0
BEDROCK_MAX_TOKENS=8192
BEDROCK_TEMPERATURE=0.7
REASONING_ENABLED=true
EXTENDED_THINKING_BUDGET=2000

# Rate Limiting (Optimized for 10-20 users)
MAX_REQUESTS_PER_MINUTE=60
MAX_CONCURRENT_REQUESTS=15
MAX_TOKENS_PER_MINUTE=180000

# Celery Configuration
CELERY_BROKER_URL=sqs://
CELERY_RESULT_BACKEND=s3://felix-s3-bucket/tara/celery-results/
CELERY_CONCURRENCY=8
CELERY_WORKER_PREFETCH_MULTIPLIER=1
CELERY_TASK_ACKS_LATE=true
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000

# SQS Specific Settings
SQS_VISIBILITY_TIMEOUT=3600
SQS_POLLING_INTERVAL=1
SQS_WAIT_TIME_SECONDS=1

# S3 Specific Settings
S3_CELERY_RESULT_EXPIRES=604800

# Monitoring & Logging
ENABLE_METRICS=true
LOG_LEVEL=INFO

# Feedback Configuration
FEEDBACK_MIN_CONFIDENCE=0.80

# Feature Flags
USE_CELERY=true
ENHANCED_MODE=true
ENABLE_S3_EXPORT=true
```

5. **Click**: Save

6. **Wait**: 5-10 minutes for redeployment

---

### Step 3: Start Celery Worker (Critical!)

**IMPORTANT**: App Runner only runs Flask, not Celery workers. You need to run a Celery worker separately.

#### Option A: Run on EC2 Instance (Recommended)

```bash
# Launch small EC2 instance (t3.micro is enough)
# SSH into it
ssh -i your-key.pem ec2-user@YOUR_EC2_IP

# Install Python and requirements
sudo yum install -y python3 python3-pip git
git clone your-repo
cd your-repo
pip3 install -r requirements.txt

# Set environment variables
export AWS_REGION=us-east-2
export S3_BUCKET_NAME=felix-s3-bucket
export S3_BASE_PATH=tara/
export CELERY_RESULT_BACKEND=s3://felix-s3-bucket/tara/celery-results/
export SQS_QUEUE_PREFIX=aiprism-

# Start Celery worker (will keep running)
celery -A celery_config.celery_app worker \
    --loglevel=info \
    --concurrency=8 \
    --queues=analysis,chat,monitoring,celery
```

#### Option B: Run in ECS Fargate

See [DEPLOYMENT_MASTER_GUIDE.md](DEPLOYMENT_MASTER_GUIDE.md) Part 3 for ECS setup.

#### Option C: Run Locally (Development Only)

```bash
# On your laptop, with same environment variables
./start_app.sh
```

**Why?** Flask handles web requests, but Celery workers process AI tasks. Both must run!

---

## ğŸ—ï¸ Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER BROWSER                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTPS
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AWS APP RUNNER (Flask App)                      â”‚
â”‚  â€¢ Handles HTTP requests                                     â”‚
â”‚  â€¢ Submits tasks to SQS                                      â”‚
â”‚  â€¢ Returns task IDs to users                                 â”‚
â”‚  URL: https://yymivpdgyd.us-east-1.awsapprunner.com         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Submit Tasks
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AMAZON SQS (Message Queues)                        â”‚
â”‚  â€¢ aiprism-analysis (document analysis)                      â”‚
â”‚  â€¢ aiprism-chat (chat queries)                               â”‚
â”‚  â€¢ aiprism-monitoring (health checks)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Poll Tasks
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CELERY WORKERS (EC2 or ECS)                          â”‚
â”‚  â€¢ Pick up tasks from SQS                                    â”‚
â”‚  â€¢ Call AWS Bedrock (Claude AI)                              â”‚
â”‚  â€¢ Store results in S3                                       â”‚
â”‚  â€¢ 8 concurrent workers                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Store Results
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             AMAZON S3 (Storage)                              â”‚
â”‚  â€¢ Documents uploaded                                        â”‚
â”‚  â€¢ Task results                                              â”‚
â”‚  â€¢ Export packages                                           â”‚
â”‚  Bucket: felix-s3-bucket                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Verification

### 1. Check Health Endpoint

```bash
curl https://yymivpdgyd.us-east-1.awsapprunner.com/health
```

**Expected Response**:
```json
{
  "status": "healthy",
  "broker": "sqs",
  "backend": "s3",
  "enhanced_mode": true,
  "celery_available": true,
  "region": "us-east-2"
}
```

---

### 2. Check SQS Queues

```bash
# List queues
aws sqs list-queues --region us-east-2

# Check message count in analysis queue
aws sqs get-queue-attributes \
    --queue-url https://sqs.us-east-2.amazonaws.com/YOUR_ACCOUNT/aiprism-analysis \
    --attribute-names All \
    --region us-east-2
```

---

### 3. Test Document Upload

1. Go to: https://yymivpdgyd.us-east-1.awsapprunner.com
2. Upload a document
3. Check task is submitted (should return task ID)
4. Wait for Celery worker to process
5. Results should appear

---

## ğŸ› Troubleshooting

### Issue: Tasks Not Processing

**Symptom**: Document uploads return task ID but never complete

**Check**:
```bash
# Check if messages are in queue
aws sqs get-queue-attributes \
    --queue-url https://sqs.us-east-2.amazonaws.com/YOUR_ACCOUNT/aiprism-analysis \
    --attribute-names ApproximateNumberOfMessages \
    --region us-east-2
```

**Fix**: Make sure Celery worker is running!

---

### Issue: "Missing bucket name" Error

**Check**: Environment variables in App Runner

**Fix**: Make sure `CELERY_RESULT_BACKEND` is set to:
```
s3://felix-s3-bucket/tara/celery-results/
```

---

### Issue: Wrong Region

**Symptom**: Tasks fail with region mismatch

**Fix**: Ensure consistency:
- App Runner env vars: `AWS_REGION=us-east-2`
- SQS queues created in: `us-east-2`
- S3 bucket region: Same as SQS
- Celery worker env vars: Same region

---

## ğŸ’° Cost Breakdown

### Current Setup (10-20 users):

| Service | Usage | Cost/Month |
|---------|-------|------------|
| **App Runner** | 2 GB RAM, always on | $25-30 |
| **SQS** | ~10K requests/day | ~$0.50 |
| **S3** | 10 GB storage, 1K requests | ~$0.50 |
| **Bedrock** | 1M tokens/day | $300-350 |
| **EC2 (t3.micro)** | Celery worker | ~$10 |
| **Data Transfer** | Minimal | ~$2 |

**Total**: ~$340-395/month

---

## ğŸš€ Scaling Options

### Current (10-20 users):
- 1 App Runner instance
- 1 EC2 t3.micro for Celery
- 8 concurrent workers
- **Cost**: ~$370/month

### Medium (50-100 users):
- 2 App Runner instances
- 2 EC2 t3.small for Celery
- 16 concurrent workers
- **Cost**: ~$850/month

### Large (100+ users):
- Switch to ECS Fargate
- Auto-scaling workers
- **Cost**: ~$1,850/month

---

## ğŸ“ Production Checklist

- [ ] SQS queues created in us-east-2
- [ ] App Runner environment variables updated
- [ ] Celery worker running on EC2/ECS
- [ ] Health endpoint returns "healthy"
- [ ] Test document upload works
- [ ] Test chat functionality works
- [ ] CloudWatch logs configured
- [ ] IAM roles have correct permissions
- [ ] S3 bucket has lifecycle policies
- [ ] Backup strategy in place

---

## ğŸ” Security Recommendations

1. **Change SECRET_KEY**: Use a strong random key
2. **Enable HTTPS**: App Runner does this by default
3. **Restrict S3 Access**: Use IAM roles, not access keys
4. **Enable CloudWatch Logs**: Monitor for errors
5. **Set Up Alerts**: SNS notifications for failures

---

## ğŸ“Š Monitoring

### CloudWatch Metrics to Watch:

1. **App Runner**:
   - Request count
   - Response time (p50, p99)
   - 4xx/5xx errors

2. **SQS**:
   - ApproximateNumberOfMessages (should be ~0)
   - ApproximateAgeOfOldestMessage

3. **Celery Worker (Custom)**:
   - Task success rate
   - Average processing time
   - Queue lag

---

## ğŸ”„ Updates and Maintenance

### To Update Code:

```bash
# Commit changes
git add .
git commit -m "Update feature X"
git push

# App Runner auto-deploys from GitHub
# Or trigger manual deployment in console
```

### To Scale Workers:

```bash
# On EC2, increase concurrency
celery -A celery_config.celery_app worker \
    --concurrency=16  # Was 8, now 16

# Or launch more EC2 instances
```

---

## âœ… Summary

**What You Need**:
1. âœ… SQS queues in us-east-2 (15 min setup)
2. âœ… Updated App Runner env vars (5 min)
3. âœ… Celery worker running (EC2 or local for dev)

**What You Get**:
- Fully scalable AI document analysis
- Multi-model fallback (5 Claude versions)
- Production-ready architecture
- ~$370/month for 10-20 users

**Current Status**: Code is ready, just needs SQS + worker!

---

**Created**: November 19, 2025
**Version**: 2.0
**Tested**: âœ… All fixes validated
**Status**: Production Ready
